 import torch
 import torch.nn as nn

 class Tudui(nn.Module):
     def __init__(self):
         super().__init__()
     def forward(self,input):
         output=input+1
         return output

 tudui=Tudui()
 x=torch.tensor(12)
 y=tudui(x)
 print(y)

 import torch
 from torch.utils.data import DataLoader

 train_data=torch.datasets.CIFAR10(root='data',transform=torch.transforms.ToTensor(),download=True)
 train_loader=DataLoader(train_data,batch_size=64,shuffle=True,drop_last=True)

 import torchvision
 from torch import nn
 import torch
 from torch.nn import Conv2d,MaxPool2d,Linear
 from torch.utils.data import DataLoader
 train_data=torchvision.datasets.CIFAR10(root='data',train=True,transform=)
 test_data=torchvision.datasets.CIFAR10(root='data',train=False,transform=)

 train_loader=DataLoader(dataset=train_data=64,shuffle=True,drop_last=False)
 test_loader=DataLoader(dataset=train)

 import torch
 from torch import nn
 from torch.nn import Conv2d, MaxPool2d, Flatten, Linear, Sequential


 class Peipei(nn.Module):
     def __init__(self) -> None:
         self.model1 = Sequential(
             Conv2d(3, 32, 5, padding=2, stride=1),
             MaxPool2d(2),#
             Conv2d(32, 32, 5, padding=2),
             MaxPool2d(2),
             Conv2d(32, 64, 5, padding=2),
             MaxPool2d(2),
             Flatten(),
             Linear(1024, 64),
             Linear(64, 10)
         )

     def forward(self, x):
         x = self.model1(x)
         return x


 peipei = Peipei()
 print(peipei)
 input = torch.ones(64, 3, 32, 32)
 output = peipei(input)
 print(output.shape)





import torch
import torch.nn as nn

class Net(nn.Module):
    def __init__(self,input_size,hidden_size,output_size) -> None:
        super().__init__()
        self.fc1 = nn.Linear(input_size,hidden_size)
        self.sigmoid = torch.nn.Sigmoid() #torch.sigmoid
        self.fc2 = nn.Linear(hidden_size,output_size) #

    def forward(self,x,w1,w2):
        self.fc1.weight.data = w1
        self.fc1.bias.data = torch.Tensor([0])
        h = self.fc1(x)
        h = self.sigmoid(h)

        self.fc2.weight.data = w2
        self.fc2.bias.data = torch.Tensor([0])
        o = self.fc2(h)
        o = self.sigmoid(o)
        return o

if __name__=='__main__':
    x = torch.tensor([0.5, 0.3])
    w1 = torch.tensor([[0.2, 0.5], [-0.4, 0.6]])
    w2 = torch.tensor([[0.1, -0.3], [-0.5, 0.8]])

    net = Net(2,2,2)
    output = net(x,w1,w2)
    # net.forward(x,w1,w2)
    print('最终的输出值为：',output)





import torch
import torch.nn as nn
class Net(nn.Module):
    def __init__(self,input_size,hidden_size,output_size) -> None:
        super().__init__()
        self.fc1 = nn.Linear(input_size,hidden_size)
        self.sigmoid = torch.nn.Sigmoid()
        self.fc2 = nn.Linear(hidden_size,output_size)
    def forward(self,x,w1,w2):
        self.fc1.weight.data = w1
        self.fc1.bias.data = torch.Tensor([0])
        out = self.fc1(x)
        out = self.sigmoid(out)

        self.fc2.weight.data=w2
        self.fc2.bias.data = torch.Tensor([0])
        output = self.fc2(out)
        output=self.sigmoid(output)
        return output

if __name__=='__main__':
    x = torch.tensor([0.5, 0.3])
    y = torch.tensor([0.23, 0.07])
    w1 = torch.tensor([[0.2, 0.5], [-0.4, 0.6]])
    w2 = torch.tensor([[0.1, -0.3], [-0.5, 0.8]])
    net = Net(2,2,2)

    loss = nn.MSELoss()  #定义损失函数
    optimizer = torch.optim.SGD(params=net.parameters(),lr=1e-2) #定义优化器

    for i in range(1000):
        output = net(x,w1,w2)
        loss_fn = loss(output,y)
        optimizer.zero_grad()
        loss_fn.backward()
        optimizer.step()
        print('损失函数的变化情况',i,loss_fn)
    print(output)